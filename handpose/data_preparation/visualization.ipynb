{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Hand] Ego Pose Visualization\n",
    "\n",
    "In this notebook you can visualize the hand ego pose annotation. Please make sure you have followed instructions in README.md to get the ground truth JSON file and undistorted Aria images. Some notes about directories to be used:\n",
    "\n",
    "- `<egoexo_output_dir>`: Directory of the data downloaded by Ego-Exo4D Downloader.\n",
    "- `<gt_output_dir>`: Output directory of hand ego pose data preparation script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.utils import get_ego_aria_cam_name, cam_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_output_dir = \"/mnt/volume2/Data/Ego4D/ego4d_baseline_data_v3\" # MODIFY\n",
    "egoexo_output_dir = \"/mnt/volume2/Data/jinxu/egoexo_public_release\" # MODIFY\n",
    "\n",
    "# Choose split and annotation type\n",
    "split = \"test\"  # MODIFY\n",
    "anno_type = \"manual\"    # MODIFY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in train split ground truth annotation\n",
    "if split in [\"train\", \"val\"]:\n",
    "    gt_anno_path = os.path.join(gt_output_dir, f\"annotation/{anno_type}/ego_pose_gt_anno_{split}_public.json\")\n",
    "else:\n",
    "    gt_anno_path = os.path.join(gt_output_dir, f\"annotation/{anno_type}/ego_pose_gt_anno_{split}_private.json\")\n",
    "assert os.path.exists(gt_anno_path), f\"{gt_anno_path} doesn't exist\"\n",
    "gt_anno = json.load(open(gt_anno_path))\n",
    "\n",
    "# Load in takes metadata\n",
    "takes = json.load(open(os.path.join(egoexo_output_dir, \"takes.json\")))\n",
    "\n",
    "# TODO: Confirm camera pose directory\n",
    "# cam_pose_dir = os.path.join(egoexo_output_dir, f\"annotations/ego_pose/hand/camera_pose\")\n",
    "cam_pose_dir = \"/mnt/volume2/Data/jinxu/suyog_new_hand_anno/camera_pose\"\n",
    "\n",
    "# Undistorted Aria image directory\n",
    "img_dir = os.path.join(gt_output_dir, f\"image/undistorted/{split}\")\n",
    "\n",
    "# take uid dict\n",
    "take_to_uid = {each_take['root_dir'] : each_take['take_uid'] for each_take in takes if each_take[\"take_uid\"] in gt_anno.keys()}\n",
    "uid_to_take = {uid:take for take, uid in take_to_uid.items()}\n",
    "\n",
    "# Helper function for visualization\n",
    "def vis_2d_hand_pose(img, two_hand_kpts_2d, take_name, frame_idx, label=\"\"):\n",
    "    ## Vis index misc ###\n",
    "    finger_index = np.array([[0,1,2,3,4],\n",
    "                             [0,5,6,7,8],\n",
    "                             [0,9,10,11,12],\n",
    "                             [0,13,14,15,16],\n",
    "                             [0,17,18,19,20]])\n",
    "    color_dict = {0:'tab:blue', 1:'tab:orange', 2:'tab:green', 3:'tab:red', 4:'tab:purple'}\n",
    "    assert isinstance(two_hand_kpts_2d, dict) and len(two_hand_kpts_2d) == 2\n",
    "\n",
    "    ## Plot\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(img)\n",
    "    for _, one_hand_kpts_2d in two_hand_kpts_2d.items():\n",
    "        if len(one_hand_kpts_2d) > 0:\n",
    "            for i, each_finger_index in enumerate(finger_index):\n",
    "                curr_finger_kpts = one_hand_kpts_2d[each_finger_index]\n",
    "                plt.plot(curr_finger_kpts[:,0], curr_finger_kpts[:,1], marker='o', markersize=2, color=color_dict[i])\n",
    "    plt.title(f\"{label} {take_name} - frame_idx={frame_idx}\", fontsize=10)\n",
    "\n",
    "\n",
    "def vis_3d_hand_pose(two_hand_kpts_3d):\n",
    "    ## Vis index misc ###\n",
    "    finger_index = np.array([[0,1,2,3,4],\n",
    "                             [0,5,6,7,8],\n",
    "                             [0,9,10,11,12],\n",
    "                             [0,13,14,15,16],\n",
    "                             [0,17,18,19,20]])\n",
    "    color_dict = {0:'tab:blue', 1:'tab:orange', 2:'tab:green', 3:'tab:red', 4:'tab:purple'}\n",
    "    assert isinstance(two_hand_kpts_3d, dict) and len(two_hand_kpts_3d) == 2\n",
    "\n",
    "    fig = plt.figure(figsize=plt.figaspect(0.5))\n",
    "    for i, hand_order in enumerate([\"left\", \"right\"]):\n",
    "        one_hand_kpts_3d = two_hand_kpts_3d[hand_order]\n",
    "        ax = fig.add_subplot(1, 2, i+1, projection='3d')\n",
    "        ax.set_title(f\"3D plot - {hand_order} hand\")\n",
    "        if len(one_hand_kpts_3d) > 0:\n",
    "            for f_ith, each_finger_index in enumerate(finger_index):\n",
    "                curr_finger_kpts = one_hand_kpts_3d[each_finger_index]\n",
    "                ax.scatter(curr_finger_kpts[:,0], curr_finger_kpts[:,1], curr_finger_kpts[:,2], color=color_dict[f_ith])\n",
    "                ax.plot3D(curr_finger_kpts[:,0], curr_finger_kpts[:,1], curr_finger_kpts[:,2], color=color_dict[f_ith])\n",
    "            ax.set_xlabel(\"X\")\n",
    "            ax.set_ylabel(\"Y\")\n",
    "            ax.set_zlabel(\"Z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found {len(gt_anno)} takes from {split} split:\")\n",
    "for uid in gt_anno:\n",
    "    print(f\"{uid_to_take[uid]:25s} {uid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_take_name = \"upenn_0715_Piano_1_2\" # MODIFY\n",
    "\n",
    "# Get selected take's annotation\n",
    "vis_take_anno = gt_anno[take_to_uid[vis_take_name]]\n",
    "print(f\"Found {len(vis_take_anno)} images from {vis_take_name} with annotated frame number:\")\n",
    "# Print all annotated frames\n",
    "print(list(vis_take_anno.keys()))\n",
    "\n",
    "# Load aria cam name and cam pose\n",
    "take = [t for t in takes if t['root_dir'] == vis_take_name][0]\n",
    "aria_name = get_ego_aria_cam_name(take)\n",
    "curr_uid = take_to_uid[vis_take_name]\n",
    "curr_cam_pose = json.load(open(os.path.join(cam_pose_dir, f\"{curr_uid}.json\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select frame_idx and visualize\n",
    "\n",
    "Pick one annotated frame and visualize 2D annotation, 3D annotation and projected 2D annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_frame_idx = 1504 # MODIFY\n",
    "vis_frame_idx = str(vis_frame_idx)\n",
    "\n",
    "# Image\n",
    "img = np.array(Image.open(os.path.join(img_dir, vis_take_name, f\"{int(vis_frame_idx):06d}.jpg\")))\n",
    "\n",
    "## 2D annotation visualization\n",
    "kpts_2d_right = np.array(vis_take_anno[vis_frame_idx]['right_hand_2d']).astype(np.float32)\n",
    "kpts_2d_left = np.array(vis_take_anno[vis_frame_idx]['left_hand_2d']).astype(np.float32)\n",
    "two_hands_kpts_2d = {\"right\": kpts_2d_right, \"left\": kpts_2d_left}\n",
    "vis_2d_hand_pose(img, two_hands_kpts_2d, vis_take_name, vis_frame_idx, \"2D GT\")\n",
    "\n",
    "## 3D annotation visualization\n",
    "kpts_3d_right = np.array(vis_take_anno[vis_frame_idx]['right_hand_3d']).astype(np.float32)\n",
    "kpts_3d_left = np.array(vis_take_anno[vis_frame_idx]['left_hand_3d']).astype(np.float32)\n",
    "# TODO: Vis\n",
    "two_hands_kpts_3d = {\"right\": kpts_3d_right, \"left\": kpts_3d_left}\n",
    "vis_3d_hand_pose(two_hands_kpts_3d)\n",
    "\n",
    "## Projected 2D annotation visualization\n",
    "intrinsics = np.array(curr_cam_pose[aria_name][\"camera_intrinsics\"]).astype(np.float32)\n",
    "kpts_2d_right_proj = cam_to_img(kpts_3d_right, intrinsics) if len(kpts_3d_right) > 0 else kpts_3d_right\n",
    "kpts_2d_left_proj = cam_to_img(kpts_3d_left, intrinsics) if len(kpts_3d_left) > 0 else kpts_3d_left\n",
    "two_hands_kpts_2d_proj = {\"right\": kpts_2d_right_proj, \"left\": kpts_2d_left_proj}\n",
    "vis_2d_hand_pose(img, two_hands_kpts_2d_proj, vis_take_name, vis_frame_idx, \"Projected 3D GT\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "human_pose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
