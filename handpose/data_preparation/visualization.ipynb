{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Hand] Ego Pose Visualization\n",
    "\n",
    "In this notebook you can visualize the hand ego pose annotation. Please make sure you have followed instructions in README.md to get the ground truth JSON file and undistorted Aria images. Some notes about directories to be used:\n",
    "\n",
    "- `<egoexo_output_dir>`: Directory of the data downloaded by Ego-Exo4D Downloader.\n",
    "- `<gt_output_dir>`: Output directory of hand ego pose data preparation script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.utils import get_ego_aria_cam_name, cam_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egoexo_output_dir = \"/media/Ego4D/Volume2/egoexo-challenge\" # MODIFY\n",
    "gt_output_dir = \"/media/Ego4D/Volume2/egoexo-challenge/egohand\" # MODIFY\n",
    "\n",
    "# Choose split and annotation type\n",
    "split = \"train\"  # MODIFY\n",
    "anno_type = \"manual\"    # MODIFY\n",
    "orientation = \"landscape\" # MODIFY\n",
    "\n",
    "assert split in [\"train\", \"val\", \"test\"], f\"Invalid split: {split}\"\n",
    "assert anno_type in [\"manual\", \"auto\"], f\"Invalid anno_type: {anno_type}\"\n",
    "assert orientation in [\"landscape\", \"portrait\"], f\"Invalid orientation: {orientation}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in train split ground truth annotation\n",
    "if split in [\"train\", \"val\"]:\n",
    "    gt_anno_path = os.path.join(gt_output_dir, f\"annotation/{anno_type}/ego_pose_gt_anno_{split}_public.json\")\n",
    "else:\n",
    "    gt_anno_path = os.path.join(gt_output_dir, f\"annotation/{anno_type}/ego_pose_gt_anno_{split}_private.json\")\n",
    "assert os.path.exists(gt_anno_path), f\"{gt_anno_path} doesn't exist\"\n",
    "gt_anno = json.load(open(gt_anno_path))\n",
    "\n",
    "# Load in takes metadata\n",
    "takes = json.load(open(os.path.join(egoexo_output_dir, \"takes.json\")))\n",
    "\n",
    "# camera pose and parameters\n",
    "cam_pose_dir = os.path.join(egoexo_output_dir, f\"annotations/ego_pose/{split}/camera_pose\")\n",
    "\n",
    "# Undistorted Aria image directory\n",
    "img_view_prefix = \"image_portrait_view\" if orientation == \"portrait\" else \"image\"\n",
    "img_dir = os.path.join(gt_output_dir, f\"{img_view_prefix}/undistorted/{split}\")\n",
    "\n",
    "# take uid dict\n",
    "take_to_uid = {each_take['take_name'] : each_take['take_uid'] for each_take in takes if each_take[\"take_uid\"] in gt_anno.keys()}\n",
    "uid_to_take = {uid:take for take, uid in take_to_uid.items()}\n",
    "\n",
    "# Helper function for visualization\n",
    "def vis_2d_bbox(img, two_hands_bbox, take_name, frame_idx, label=\"\"):\n",
    "    assert isinstance(two_hands_bbox, dict) and len(two_hands_bbox) == 2\n",
    "\n",
    "    ## Plot\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(img)\n",
    "    for _, one_hand_bbox in two_hands_bbox.items():\n",
    "        if len(one_hand_bbox) > 0:\n",
    "            plt.plot([one_hand_bbox[0],one_hand_bbox[2]], [one_hand_bbox[1],one_hand_bbox[1]], 'r')\n",
    "            plt.plot([one_hand_bbox[0],one_hand_bbox[0]], [one_hand_bbox[1],one_hand_bbox[3]], 'r')\n",
    "            plt.plot([one_hand_bbox[0],one_hand_bbox[2]], [one_hand_bbox[3],one_hand_bbox[3]], 'r')\n",
    "            plt.plot([one_hand_bbox[2],one_hand_bbox[2]], [one_hand_bbox[1],one_hand_bbox[3]], 'r')\n",
    "    plt.title(f\"{label} {take_name} - frame_idx={frame_idx}\", fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def vis_2d_hand_pose(img, two_hand_kpts_2d, take_name, frame_idx, label=\"\"):\n",
    "    ## Vis index misc ###\n",
    "    finger_index = np.array([[0,1,2,3,4],\n",
    "                             [0,5,6,7,8],\n",
    "                             [0,9,10,11,12],\n",
    "                             [0,13,14,15,16],\n",
    "                             [0,17,18,19,20]])\n",
    "    color_dict = {0:'tab:blue', 1:'tab:orange', 2:'tab:green', 3:'tab:red', 4:'tab:purple'}\n",
    "    assert isinstance(two_hand_kpts_2d, dict) and len(two_hand_kpts_2d) == 2\n",
    "\n",
    "    ## Plot\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(img)\n",
    "    for _, one_hand_kpts_2d in two_hand_kpts_2d.items():\n",
    "        if len(one_hand_kpts_2d) > 0:\n",
    "            for i, each_finger_index in enumerate(finger_index):\n",
    "                curr_finger_kpts = one_hand_kpts_2d[each_finger_index]\n",
    "                plt.plot(curr_finger_kpts[:,0], curr_finger_kpts[:,1], marker='o', markersize=2, color=color_dict[i])\n",
    "    plt.title(f\"{label} {take_name} - frame_idx={frame_idx}\", fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n",
    "def vis_3d_hand_pose(two_hand_kpts_3d):\n",
    "    ## Vis index misc ###\n",
    "    finger_index = np.array([[0,1,2,3,4],\n",
    "                             [0,5,6,7,8],\n",
    "                             [0,9,10,11,12],\n",
    "                             [0,13,14,15,16],\n",
    "                             [0,17,18,19,20]])\n",
    "    color_dict = {0:'tab:blue', 1:'tab:orange', 2:'tab:green', 3:'tab:red', 4:'tab:purple'}\n",
    "    assert isinstance(two_hand_kpts_3d, dict) and len(two_hand_kpts_3d) == 2\n",
    "\n",
    "    fig = plt.figure(figsize=plt.figaspect(0.5))\n",
    "    for i, hand_order in enumerate([\"left\", \"right\"]):\n",
    "        one_hand_kpts_3d = two_hand_kpts_3d[hand_order]\n",
    "        ax = fig.add_subplot(1, 2, i+1, projection='3d')\n",
    "        ax.set_title(f\"3D plot - {hand_order} hand\")\n",
    "        if len(one_hand_kpts_3d) > 0:\n",
    "            for f_ith, each_finger_index in enumerate(finger_index):\n",
    "                curr_finger_kpts = one_hand_kpts_3d[each_finger_index]\n",
    "                ax.scatter(curr_finger_kpts[:,0], curr_finger_kpts[:,1], curr_finger_kpts[:,2], color=color_dict[f_ith])\n",
    "                ax.plot3D(curr_finger_kpts[:,0], curr_finger_kpts[:,1], curr_finger_kpts[:,2], color=color_dict[f_ith])\n",
    "            ax.set_xlabel(\"X\")\n",
    "            ax.set_ylabel(\"Y\")\n",
    "            ax.set_zlabel(\"Z\")\n",
    "        ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found {len(gt_anno)} takes from {split} split:\")\n",
    "for uid in gt_anno:\n",
    "    print(f\"{uid_to_take[uid]:25s} {uid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_take_name = \"upenn_0717_Piano_1_2\" # MODIFY\n",
    "\n",
    "# Get selected take's annotation\n",
    "vis_take_anno = gt_anno[take_to_uid[vis_take_name]]\n",
    "print(f\"Found {len(vis_take_anno)} images from {vis_take_name} with annotated frame number:\")\n",
    "# Print all annotated frames\n",
    "print(list(vis_take_anno.keys()))\n",
    "\n",
    "# Load aria cam name and cam pose\n",
    "take = [t for t in takes if t['take_name'] == vis_take_name][0]\n",
    "aria_name = get_ego_aria_cam_name(take)\n",
    "curr_uid = take_to_uid[vis_take_name]\n",
    "curr_cam_pose = json.load(open(os.path.join(cam_pose_dir, f\"{curr_uid}.json\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select frame_idx and visualize\n",
    "\n",
    "Pick one annotated frame and visualize 2D annotation, 3D annotation and projected 2D annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_frame_idx = 547 # MODIFY\n",
    "vis_frame_idx = str(vis_frame_idx)\n",
    "\n",
    "# Image\n",
    "img = np.array(Image.open(os.path.join(img_dir, vis_take_name, f\"{int(vis_frame_idx):06d}.jpg\")))\n",
    "\n",
    "## hand bounding box visualization\n",
    "bbox_right = np.array(vis_take_anno[vis_frame_idx]['right_hand_bbox']).astype(np.float32)\n",
    "bbox_left = np.array(vis_take_anno[vis_frame_idx]['left_hand_bbox']).astype(np.float32)\n",
    "two_hands_bbox = {\"right\": bbox_right, \"left\": bbox_left}\n",
    "vis_2d_bbox(img, two_hands_bbox, vis_take_name, vis_frame_idx, \"bbox\")\n",
    "\n",
    "## 2D annotation visualization\n",
    "kpts_2d_right = np.array(vis_take_anno[vis_frame_idx]['right_hand_2d']).astype(np.float32)\n",
    "kpts_2d_left = np.array(vis_take_anno[vis_frame_idx]['left_hand_2d']).astype(np.float32)\n",
    "two_hands_kpts_2d = {\"right\": kpts_2d_right, \"left\": kpts_2d_left}\n",
    "vis_2d_hand_pose(img, two_hands_kpts_2d, vis_take_name, vis_frame_idx, \"2D GT\")\n",
    "\n",
    "## 3D annotation visualization\n",
    "kpts_3d_right = np.array(vis_take_anno[vis_frame_idx]['right_hand_3d']).astype(np.float32)\n",
    "kpts_3d_left = np.array(vis_take_anno[vis_frame_idx]['left_hand_3d']).astype(np.float32)\n",
    "# rotate 3D annotations if in portrait view\n",
    "if orientation == \"portrait\":\n",
    "    print(kpts_3d_right.shape)\n",
    "    R = np.array([[0,-1,0], [1,0,0], [0,0,1]])\n",
    "    print(R)\n",
    "    kpts_3d_right = (R @ kpts_3d_right.T).T\n",
    "    kpts_3d_left = (R @ kpts_3d_left.T).T\n",
    "two_hands_kpts_3d = {\"right\": kpts_3d_right, \"left\": kpts_3d_left}\n",
    "vis_3d_hand_pose(two_hands_kpts_3d)\n",
    "\n",
    "## Projected 2D annotation visualization\n",
    "intrinsics = np.array(curr_cam_pose[aria_name][\"camera_intrinsics\"]).astype(np.float32)\n",
    "kpts_2d_right_proj = cam_to_img(kpts_3d_right, intrinsics) if len(kpts_3d_right) > 0 else kpts_3d_right\n",
    "kpts_2d_left_proj = cam_to_img(kpts_3d_left, intrinsics) if len(kpts_3d_left) > 0 else kpts_3d_left\n",
    "two_hands_kpts_2d_proj = {\"right\": kpts_2d_right_proj, \"left\": kpts_2d_left_proj}\n",
    "vis_2d_hand_pose(img, two_hands_kpts_2d_proj, vis_take_name, vis_frame_idx, \"Projected 3D GT\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
